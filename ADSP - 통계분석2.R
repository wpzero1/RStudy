
# 예제04 - 식이요법 바업을 적용한 닭 데이터

install.packages("MASS")
library(MASS)

# 1번 닭에게 식이요법 방법 1을 적용한 데이터만 조회해 변수에 할당

 # weight : 무게, Time : 시간, Chick : 닭 번호, Diet : 식이요법 방법 번호

chick<-ChickWeight[ChickWeight$Diet==1,]
chick

 #데이터 셋에서 1번 닭만 조회

chick<-ChickWeight[ChickWeight$Chick==1,]
chick

 #시간의 경과에 따른 닭들의 무게를 단순회귀분석
lm(weight~Time,chick)

 #회귀식은 weight=7.988Time+24.465

m1<-lm(weight~Time,chick)
summary(m1)

 # F통계량=232.7, p-value는 0.01보다 작고, 결정계수값이 95%로 매우 높음. 통계적으로 매우 유의함.


# 예제 05 모델 진단 그래프 *** (cars 데이터)
data(cars)
cars #speed, dist
str(cars)
head(cars)

m<-lm(dist~speed,cars)
summary(m)
plot(m) # 4번 실행하여 각 그래프를 보자.

# Residuals vs Fitted

#y축은 잔차. 선형회귀에서 오차는 평균이 0이고, 분산이 일정한 정규분포 가정.
 #y값은 기울기가 0인 직선이 이상적임

#Normal Q-Q
 # 잔차가 정규분포를 잘 따르고 있는지 확인하는 그래프로, 잔차들이 그래프 선상에 있어야 이상적

#Scale-Location
 #y축이 표준화 잔차를 나타냄. 기울기 0인 직선이 이상적 (멀리떨어질수록 이상치)

#Residuals vs Leverage
 #우측 상하단에는 빨간색으로 Cook's Distance가 점선으로 표시되어있다. 일반적으로 1값이 넘어가면 관측치를 영향점으로 판별


#다중공선성
 # 다중회귀 결과 해석시 중요
 # 모형의 일부 예측변수가 다른 예측변수와 상관되어있을 때 발생하는 조건. 회귀계수 분산을 증가시켜 불안정하게 만듬
 # vif함수를 사용해 VIF값을 간단히 구하고, 4가 넘으면 다중공선성 존재한다고 봄
 # 해결방안 : 높은 상관관계가 있는 예측변수를 모형에서 제거

# 
# 5) 최적 회귀방정식의 선택 : 설명변수의 선택
#  1. y에 영향을 미칠 수 있는 모든 설명변수 x들을 y예측에 참여시킴
#  2. 가능한 적은 수의 설명변수를 포함시켜야함
 # 서로 이율배반적이므로 타협이 이뤄져야함. 선택해야하는것.

# 6) 설명변수 선택 방법
#  (1) 모든 가능한 조합의 회귀분석
#     AIC, BIC 기준으로 가장 적합한 회귀모형 선택
#     OLS method(최소자승법)에서 R-square와 비슷한 역할을 하는데, 적합성을 측정해주는 지표임. 값이 작은 것이 좋음.
# 
#  (2) 단계적 변수선택 **
#    1. 단계별 선택 : 기준 통계치에 가장 도움 안되는 변수 삭제, 모델에서 빠져있는 변수중에서 변수 추가(개선 용도)
#    2. 후진 제거법 : 가장 도움 안되는 변수를 하나씩 제거
#    3. 전진 선택법 : 절편만 있는 모델에서 통계치를 가장 많이 개선시키는 변수 추가
#     --> step()함수로 수행
#    
   
# 예시 06 후진제거법

x1<-c(7,1,11,11,7,11,3,1,2,21,1,11,10)
x2<-c(26,29,56,31,52,55,71,31,54,47,40,66,68)
x3<-c(6,15,8,8,6,9,17,22,18,4,23,9,8)
x4<-c(60,52,20,47,33,22,6,44,22,26,34,12,12)
y<-c(78.5,74.3,104.3,87.6,95.9,109.2,102.7,72.5,93.1,115.9,83.8,113.3,109.4)
df<-data.frame(x1,x2,x3,x4,y)
head(df)

 #회귀분석
a<-lm(y~x1+x2+x3+x4,data=df)
a
summary(a)

# 유의확률이 가장 높은 x3를 제거하고 다시 회귀분석
a<-lm(y~x1+x2+x4,data=df)
a
summary(a)
 #결정계수가 0.9736 -> 0.9764 로 높아짐

# 유의확률이 높은 x4 제거하고 회귀분석
a<-lm(y~x1+x2,data=df)
a
summary(a)

 #F통계량 및 p값이 유의수준 5% 하에서 통계적으로 유의하고, 설명변수 x1,x2 유의확률값이 유의하므로
 #여기서 변수제거 멈춤 **
 #최종 회귀식은 y=52.57735+1.46831x1+0.66225x2 로 추정


# 3. 정규화 선형회귀 : 선형회귀계수에 대한 제약조건을 추가하여, 과적합을 막는 방법임
 #일반적으로 딥러닝에서 overfitting 문제를 해결하는 방법 : 더 많은 데이터 사용, Cross Validation, 정규화

 # 1) 릿지회귀 (Ridge) : 제약식은 L2norm, 변수선택 불가능, 변수간 상관관계 높으면 좋은 성능
  # 평균제곱오차(MSE)를 최소화하면서 회귀계수 벡터의 L2 norm을 최소화하는 기법.

#  2) 라소회귀(lasso) : L1norm, 변수선택 가능, 변수간 상관관계가 높으면 성능 떨어짐

  # 릿지회귀와 동일하지만 L1 norm을 제약한다는 점이 다름. 가중치의 절댓값의 합을 최소화하는 것을 제약 조건으로 함

#  3) 엘라스틱넷(Elastic Net) : 제약식에 norm 모두를 쓰는 기법 (L1norm + L2norm), 변수 선택 가능, 변수간 상관관계를 반영한 정규화


# 03. 다변량분석
  # : 주요 목표중 하나는, 간단한 형식으로 데이터 요약 - 반응변수와 설명변수간의 관계 쉽게 이해

 # 1. 상관분석 ** : 두 변수 간의 관련성 파악
   # 서열척도 - 스피어만 상관분석
   # 등간, 비율척도 - 피어슨 상관분석, 편상관분석

 # *공분산 : 두 확률변수가 얼마나 같이 변하는지 측정

 # 1) 상관계수 r은 -1=< r =< +1 1에 가까울수록 상관이 높고 0에 가까울수록 상관이 낮다
     # r=0은 두 변수 사이에 직선적 상관관계가 없음을 의미, 0상관 또는 무상관이라 부름
     # 어떤 관계도 존재하지 않는다는 뜻은 아니다. 산점도를 먼저 그릴 것.

#     
# 2) 상관분석의 절차 *
#  1. 산점도를 그려서 두 변수의 대략적 관계 알아보기
#  2. 상관계수에 필요한 통계량을 구함
#  3. 상관계수를 구함
#  4. 모상관계수에 대한 유의성 검정
#  5. 결정계수 구함
#  6. 상관계수와 결정계수 제시, 상관분석 결과 설명
# 
# 검정은 Cor.test() 함수 이용
# 
# 3) 피어슨 상관계수 vs 스피어만 상관계수
# 피어슨 : 두 변수의 선형관계 크기 측정, 연속형 변수만 가능 (국어 점수와 영어 점수)
# 스피어만 : 두 변수간의 비선형관계도 측정 가능, 이산형도 가능 (국어성적 석차와 영어성적 석차 관계)
# 
# 4) 결정계수 *
#   1. 회귀의 분산분석에서 총제곱합(총변동, SST) = 회귀제곱합(설명된 변동, SSR) + 오차제곱합(SSE)
#   2. R제곱(결정계수) = 회귀제곱합(SSR)/총제곱합(SST)
#   3. 결정계수는 독립변수(X)가 종속변수(Y)를 얼마나 설명할 수 있는지를 알려주고, 이 값이 클수록 회귀방정식과 상관계수의 설명력이 높아진다.
#   
#   
#   2. 다차원 척도법(MDS, Multidimensional Scaling) *
#     개체들 사이의 유사성/비유사성 측정하여 2차원 또는 2차원 공간상에 표현하는 분석방법.
#   개체들 간의 근접성 시각화하여 데이터의 잠재 패턴, 구조 찾아내는 통계기법


# 예제 08
loc<-cmdscale(eurodist)
loc #2차원 도시 사이의 거리 매핑
x<-loc[,1] #2차원 값을 각각 x,y 좌표에 배정
y<-loc[,2]
plot(x,y,type="n",main="eurodist") #type=n 그래프 유형으로 아무것도 그리지 않음. l은 선, p는 점
text(x,y,rownames(loc),cex=.8,col="red") # text() : 그래프에 문자열 그리는데 사용함
abline(v=0,h=0) #v는 수직선, h는 수평선 직선 추가

 #즉 유사성 지각에 대한 정보들을 시각적으로 표시한다. Euclidean 거리로 측정함.

# 3. 주성분 분석(PCA, Principal Component Analysis) ***
 # 데이터에 많은 변수가 있을 때 변수의 수를 줄이는 차원 감소 기법
 # 데이터의 패턴 찾는 도구.

library(datasets)
data("USArrests") #USAreests는 미국 50개주의 인구 10만명당 살인, 폭행, 강간으로 인한 체포의 수와 도시 인구 비율을 나타냄
head(USArrests)

fit<-princomp(USArrests,cor=TRUE) #주성분분석 함수 princomp(), 상관계수 행렬을 사용
summary(fit) #4개 주성분의 표준편차, 분산비율, 누적비율
 #첫번째 주성분분석 하나가 전체 분산의 62%를 설명, 두번짼 24.7%.

loadings(fit) # 주성분들의 로딩 벡터를 나타냄
plot(fit,type="lines") #스크리도표(Scree plot). 고유값이 1보다 크며 하나의 요인이 변수 1개 이상의 분산을 설명한다는 의미.
#1보다 작다면 요인으로서 의미 없음

#요인분석과는 조금 다르다. 요인분석은 자료의 축소라는 의미도 포함해, 데이터에 내재적 속성까지 찾아냄

biplot(fit)
 #제1주성분과 제2주성분만 구해 2차원의 점그래프로 표현함.

# 04. 시계열 예측 : 관측치가 시간적 순서를 가진 것. 일정 시점에 조사된 데이터는 횡단 자료라고 한다.

 # 1. 정상성 ** : 시계열 수준과 분산에 체계적인 변화가 없고, 주기적 변동이 없음.
   # 조건들 3개.
    # (1) 평균값은 시간 t에 관계없이 일정하다.
    # (2) 분산값은 시간 t에 관계없이 일정하다.
    # (3) 공분산은 시간 t에 의존하지 않고 오직 시차에만 의존한다.
 # --> 하나라도 만족 못하는 경우는 비정상시계열 (대부분)

# 2. 비정상시계열을 정상시계열로 전환하는 방법
  # (1) 원시계열에 차분(현재 시점에서 바로 전 시점의 자료 값 빼는 것)
  # (2) 계절성을 갖는 것은 계절차분 사용
  # (3) 분산이 일정하지 않는 경우, 원계열에 자연로그 취하기

# 3. 시계열 모형
 # 1) 자기회귀모형 : 자신의 과거 값을 사용함. 현시점의 시계열 자료에 과거 1시점 이전의 자료만 영향을 준다면 1차 자기회귀모형, AR(1) 모형이라고 함.

  # 백색잡음 과정 : 시계열 et의 평균이 0이고 분산이 일정한 값 2시그마, 자기공분산이 0인경우.

 # 2) 이동평균모형 : 최근 데이터의 평균(혹은 중앙치)을 예측치로 사용. 각 과거치에는 동일한 가중치가 주어짐

 # 3) 자기회귀누적이동 모형(ARIMA) : 대부분 많은 시계열 자료가 이것을 따름. 비정상시계열 모형임.

# 4) 자기회귀모형평균 모형 식별

# 5) 분해 시계열 **
 # (1) 추세요인 : 자료가 어떤 특정한 형태를 취할 때.
 # (2) 계절요인 : 계절에 따라 고정된 주기에 따라 자료 변화
 # (3) 순환요인 : 알려지지 않은 주기를 따를 때
 # (4) 불규칙 요인 : 회귀분석에서 오차에 해당함.

 # 예제10 아스완댐에서 측정한 나일강의 연간 유입량 시계열 데이터
Nile
plot(Nile)
 #비계절성 데이터. 그러나 평균이 변화하는 추세를 보여 정상성 만족 x

#diff로 차분
Nile.diff1<-diff(Nile,differences=1)
plot(Nile.diff1)
#1차 차분으로는 아직 평균 일정하지 않아 2차 차분함

Nile.diff2<-diff(Nile,diffrences=2)
plot(Nile.diff2)
# 평균과 분산이 시간이 지남에 따라 어느정도 일정한 정상성을 만족함

# 예제 11 영국 내 월별 폐질환 사망자 시계열 자료
ldeaths
plot(ldeaths)
 # 연도별로 계절성을 띤다. 주기별로 사망자수 급감

 # decompose() 함수로 시계열 자료를 4가지 요인으로 분해함
ldeaths.decompose<-decompose(ldeaths)
ldeaths.decompose$seasonal
plot(ldeaths.decompose)

# 계절요인을 추정해 그 값을 원시계열 자료에서 빼면 적절하게 조정할 수 있음
ldeaths.decompose.adj<-ldeaths-ldeaths.decompose$seasonal
plot(ldeaths.decompose.adj)

# 4. ARIMA 모델 적합 및 결정 ** : 자기상관함수 알아보기위해 acf 함수 사용

acf(Nile.diff2, lag.max = 20)
acf(Nile.diff2, lag.max=20,plot=FALSE)
 #래그 3에서 자기상관계수의 값은 0.027. 래그 0과 8을 제외하고 모두 신뢰구간에 있음

pacf(Nile.diff2,lag.max=20)
pacf(Nile.diff2,lag.max=20,plot=FALSE)
#부분자기함수. lag1~7은 음수, lag8에서 절단된다.

install.packages("forecast")
library(forecast)
auto.arima(Nile)
 # 패키지 안에 있는 함수 이용해 적절한 ARIMA 모형 결정

 #ARIMA 모형을 이용한 예측
Nile.arima<-arima(Nile,order=c(1,1,1)) #데이터에 모형을 적합한 후 forecast함수 이용해 미래 수치값 예측
Nile.arima

#이를 통해 미래 50개연도 나일강 연간 유입량 예측
Nile.forecast<-forecast(Nile.arima,h=50) #h=연도
Nile.forecast
plot(Nile.forecast)

